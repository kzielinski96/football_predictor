{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks part\n",
    "### Same predictions as in the machine learning part using MLP classiffiers provided by Scikit-Learn and TensorFlow libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsługa środowisk Python 2 i Python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Importowanie popularnych modułów\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# W celu zachowania powtarzalności wyników w kolejnych przebiegach\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generowanie ładnych wykresów\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Lokacja, w której będą zapisywane rysunki\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"preparing_dataset\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"pictures\", CHAPTER_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(PROJECT_ROOT_DIR, \"pictures\", CHAPTER_ID, fig_id)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving an image\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "FOOTBALL_PATH_SP = os.path.join(\"datasets\", \"spain\")\n",
    "football_path_sp = FOOTBALL_PATH_SP\n",
    "\n",
    "FOOTBALL_PATH_EN = os.path.join(\"datasets\", \"england\")\n",
    "football_path_en = FOOTBALL_PATH_EN\n",
    "\n",
    "FOOTBALL_PATH_FR = os.path.join(\"datasets\", \"france\")\n",
    "football_path_fr = FOOTBALL_PATH_FR\n",
    "\n",
    "FOOTBALL_PATH_GE = os.path.join(\"datasets\", \"germany\")\n",
    "football_path_ge = FOOTBALL_PATH_GE\n",
    "\n",
    "FOOTBALL_PATH_IT = os.path.join(\"datasets\", \"italy\")\n",
    "football_path_it = FOOTBALL_PATH_IT\n",
    "\n",
    "def load_football_data(football_path, file):\n",
    "    csv_path = os.path.join(football_path, file)\n",
    "    return pd.read_csv(csv_path, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_sp = load_football_data(FOOTBALL_PATH_SP, \"spain.csv\")\n",
    "football_en = load_football_data(FOOTBALL_PATH_EN, \"england.csv\")\n",
    "football_fr = load_football_data(FOOTBALL_PATH_FR, \"france.csv\")\n",
    "football_ge = load_football_data(FOOTBALL_PATH_GE, \"germany.csv\")\n",
    "football_it = load_football_data(FOOTBALL_PATH_IT, \"italy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "football = football_fr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4280 entries, 0 to 4279\n",
      "Data columns (total 26 columns):\n",
      "Div         4280 non-null object\n",
      "Date        4280 non-null object\n",
      "HomeTeam    4280 non-null object\n",
      "AwayTeam    4280 non-null object\n",
      "FTHG        4280 non-null float64\n",
      "FTAG        4280 non-null float64\n",
      "FTR         4280 non-null object\n",
      "HTHG        4279 non-null float64\n",
      "HTAG        4279 non-null float64\n",
      "HTR         4279 non-null object\n",
      "HS          4279 non-null float64\n",
      "AS          4279 non-null float64\n",
      "HST         4279 non-null float64\n",
      "AST         4279 non-null float64\n",
      "HF          4277 non-null float64\n",
      "AF          4277 non-null float64\n",
      "HY          4279 non-null float64\n",
      "AY          4279 non-null float64\n",
      "HR          4279 non-null float64\n",
      "AR          4279 non-null float64\n",
      "B365H       4279 non-null float64\n",
      "B365D       4279 non-null float64\n",
      "B365A       4279 non-null float64\n",
      "BWH         4280 non-null float64\n",
      "BWD         4280 non-null float64\n",
      "BWA         4280 non-null float64\n",
      "dtypes: float64(20), object(6)\n",
      "memory usage: 869.5+ KB\n"
     ]
    }
   ],
   "source": [
    "football.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "football = football.dropna(subset=[\"Date\"])\n",
    "football = pd.DataFrame(football).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "homeTeamList = football[\"HomeTeam\"].tolist() \n",
    "awayTeamList = football[\"AwayTeam\"].tolist()\n",
    "fTRList = football[\"FTR\"].tolist()\n",
    "hTRList = football[\"HTR\"].tolist()\n",
    "divList = football[\"Div\"].tolist()\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "\n",
    "labelEncoder.fit(homeTeamList)\n",
    "label = labelEncoder.transform(homeTeamList)\n",
    "football['homeTeam']=pd.Series(label)\n",
    "\n",
    "labelEncoder.fit(awayTeamList)\n",
    "label = labelEncoder.transform(awayTeamList)\n",
    "football['awayTeam']=pd.Series(label)\n",
    "\n",
    "labelEncoder.fit(hTRList)\n",
    "label = labelEncoder.transform(hTRList)\n",
    "football['hTR']=pd.Series(label)\n",
    "\n",
    "labelEncoder.fit(fTRList)\n",
    "label = labelEncoder.transform(fTRList)\n",
    "football['fTR']=pd.Series(label)\n",
    "\n",
    "labelEncoder.fit(divList)\n",
    "label = labelEncoder.transform(divList)\n",
    "football['div']=pd.Series(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>...</th>\n",
       "      <th>BWH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>homeTeam</th>\n",
       "      <th>awayTeam</th>\n",
       "      <th>hTR</th>\n",
       "      <th>fTR</th>\n",
       "      <th>div</th>\n",
       "      <th>DayOfTheYear</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>09/08/08</td>\n",
       "      <td>Auxerre</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.55</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>09/08/08</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Caen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.35</td>\n",
       "      <td>6.25</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>09/08/08</td>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Nice</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.90</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>09/08/08</td>\n",
       "      <td>Le Mans</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.75</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1</td>\n",
       "      <td>09/08/08</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Paris SG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.75</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F1</td>\n",
       "      <td>09/08/08</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Lille</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F1</td>\n",
       "      <td>09/08/08</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.35</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F1</td>\n",
       "      <td>09/08/08</td>\n",
       "      <td>Sochaux</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.50</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1</td>\n",
       "      <td>09/08/08</td>\n",
       "      <td>Valenciennes</td>\n",
       "      <td>St Etienne</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.75</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1</td>\n",
       "      <td>10/08/08</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>Toulouse</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.85</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1</td>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Caen</td>\n",
       "      <td>Valenciennes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>F1</td>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Le Mans</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>F1</td>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.75</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>F1</td>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.20</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>F1</td>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Paris SG</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>F1</td>\n",
       "      <td>16/08/08</td>\n",
       "      <td>St Etienne</td>\n",
       "      <td>Sochaux</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.15</td>\n",
       "      <td>4.40</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>F1</td>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Toulouse</td>\n",
       "      <td>Le Havre</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>F1</td>\n",
       "      <td>17/08/08</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.45</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>F1</td>\n",
       "      <td>17/08/08</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1.75</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>F1</td>\n",
       "      <td>17/08/08</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Auxerre</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.35</td>\n",
       "      <td>6.25</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Div      Date      HomeTeam      AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
       "0   F1  09/08/08       Auxerre        Nantes   2.0   1.0   H   1.0   0.0   H   \n",
       "1   F1  09/08/08      Bordeaux          Caen   2.0   1.0   H   0.0   1.0   A   \n",
       "2   F1  09/08/08      Le Havre          Nice   1.0   0.0   H   0.0   0.0   D   \n",
       "3   F1  09/08/08       Le Mans       Lorient   0.0   1.0   A   0.0   0.0   D   \n",
       "4   F1  09/08/08        Monaco      Paris SG   1.0   0.0   H   0.0   0.0   D   \n",
       "5   F1  09/08/08         Nancy         Lille   0.0   0.0   D   0.0   0.0   D   \n",
       "6   F1  09/08/08        Rennes     Marseille   4.0   4.0   D   1.0   3.0   A   \n",
       "7   F1  09/08/08       Sochaux      Grenoble   1.0   2.0   A   0.0   0.0   D   \n",
       "8   F1  09/08/08  Valenciennes    St Etienne   1.0   0.0   H   1.0   0.0   H   \n",
       "9   F1  10/08/08          Lyon      Toulouse   3.0   0.0   H   1.0   0.0   H   \n",
       "10  F1  16/08/08          Caen  Valenciennes   3.0   1.0   H   3.0   1.0   H   \n",
       "11  F1  16/08/08         Lille       Le Mans   1.0   3.0   A   0.0   2.0   A   \n",
       "12  F1  16/08/08        Nantes        Monaco   1.0   1.0   D   0.0   1.0   A   \n",
       "13  F1  16/08/08          Nice         Nancy   2.0   1.0   H   1.0   1.0   D   \n",
       "14  F1  16/08/08      Paris SG      Bordeaux   1.0   0.0   H   0.0   0.0   D   \n",
       "15  F1  16/08/08    St Etienne       Sochaux   2.0   1.0   H   2.0   0.0   H   \n",
       "16  F1  16/08/08      Toulouse      Le Havre   2.0   1.0   H   0.0   1.0   A   \n",
       "17  F1  17/08/08      Grenoble        Rennes   1.0   0.0   H   1.0   0.0   H   \n",
       "18  F1  17/08/08       Lorient          Lyon   0.0   0.0   D   0.0   0.0   D   \n",
       "19  F1  17/08/08     Marseille       Auxerre   4.0   0.0   H   1.0   0.0   H   \n",
       "\n",
       "    ...   BWH   BWD   BWA  homeTeam  awayTeam  hTR  fTR  div  DayOfTheYear  \\\n",
       "0   ...  2.05  3.00  3.55         5        26    3    2    0           222   \n",
       "1   ...  1.55  3.35  6.25         7        10    1    2    0           222   \n",
       "2   ...  2.40  2.95  2.90        15        27    2    2    0           222   \n",
       "3   ...  1.95  3.10  3.75        16        19    2    0    0           222   \n",
       "4   ...  2.40  3.10  2.75        23        29    2    2    0           222   \n",
       "5   ...  2.25  3.00  3.10        25        18    2    1    0           222   \n",
       "6   ...  2.85  3.10  2.35        31        21    1    1    0           222   \n",
       "7   ...  1.80  3.10  4.50        32        13    2    0    0           222   \n",
       "8   ...  2.50  2.95  2.75        37        33    3    2    0           222   \n",
       "9   ...  1.35  4.00  8.85        20        35    3    2    0           223   \n",
       "10  ...  2.10  3.00  3.50        10        37    3    2    0           229   \n",
       "11  ...  1.90  3.00  4.20        18        16    1    0    0           229   \n",
       "12  ...  2.50  2.95  2.75        26        23    1    1    0           229   \n",
       "13  ...  2.25  2.90  3.20        27        25    2    2    0           229   \n",
       "14  ...  2.30  3.00  3.00        29         7    2    2    0           229   \n",
       "15  ...  1.80  3.15  4.40        33        32    3    2    0           229   \n",
       "16  ...  2.10  3.00  3.45        35        15    1    2    0           229   \n",
       "17  ...  2.85  2.90  2.45        13        31    3    2    0           230   \n",
       "18  ...  4.40  3.35  1.75        19        20    2    1    0           230   \n",
       "19  ...  1.55  3.35  6.25        21         5    3    2    0           230   \n",
       "\n",
       "    Year  \n",
       "0   2008  \n",
       "1   2008  \n",
       "2   2008  \n",
       "3   2008  \n",
       "4   2008  \n",
       "5   2008  \n",
       "6   2008  \n",
       "7   2008  \n",
       "8   2008  \n",
       "9   2008  \n",
       "10  2008  \n",
       "11  2008  \n",
       "12  2008  \n",
       "13  2008  \n",
       "14  2008  \n",
       "15  2008  \n",
       "16  2008  \n",
       "17  2008  \n",
       "18  2008  \n",
       "19  2008  \n",
       "\n",
       "[20 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "dates = pd.Series(football['Date'])\n",
    "dates = pd.to_datetime(dates, format = '%d/%m/%y')\n",
    "days = []\n",
    "years = []\n",
    "\n",
    "for i in dates:\n",
    "    d = i.dayofyear\n",
    "    days.append(d)\n",
    "    y = i.year\n",
    "    years.append(y)\n",
    "    \n",
    "x = pd.Series(days)\n",
    "y = pd.Series(years)\n",
    "football[\"DayOfTheYear\"] = x\n",
    "football[\"Year\"] = y\n",
    "football.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "football = football.drop(columns = ['div', 'Div','Date', 'HomeTeam', 'AwayTeam', 'HTR', 'FTR', 'FTHG', 'HTHG', 'FTAG', 'HTAG'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>...</th>\n",
       "      <th>B365A</th>\n",
       "      <th>BWH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>homeTeam</th>\n",
       "      <th>awayTeam</th>\n",
       "      <th>hTR</th>\n",
       "      <th>fTR</th>\n",
       "      <th>DayOfTheYear</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.55</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.35</td>\n",
       "      <td>6.25</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.90</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.75</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.75</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HS    AS   HST  AST    HF    AF   HY   AY   HR   AR  ...  B365A   BWH  \\\n",
       "0  10.0  15.0   5.0  4.0  19.0  18.0  2.0  0.0  0.0  0.0  ...   3.75  2.05   \n",
       "1  24.0   8.0  11.0  1.0  10.0  22.0  3.0  4.0  0.0  0.0  ...   6.50  1.55   \n",
       "2  14.0  15.0   4.0  3.0  24.0  21.0  1.0  2.0  0.0  0.0  ...   3.40  2.40   \n",
       "3  10.0  12.0   2.0  1.0  22.0  16.0  2.0  2.0  0.0  0.0  ...   3.80  1.95   \n",
       "4  10.0   7.0   4.0  3.0  10.0  15.0  1.0  2.0  0.0  0.0  ...   3.10  2.40   \n",
       "\n",
       "    BWD   BWA  homeTeam  awayTeam  hTR  fTR  DayOfTheYear  Year  \n",
       "0  3.00  3.55         5        26    3    2           222  2008  \n",
       "1  3.35  6.25         7        10    1    2           222  2008  \n",
       "2  2.95  2.90        15        27    2    2           222  2008  \n",
       "3  3.10  3.75        16        19    2    0           222  2008  \n",
       "4  3.10  2.75        23        29    2    2           222  2008  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "football.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x,y = football.loc[:,football.columns != 'fTR'], football.loc[:,'fTR']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp_clf = MLPClassifier(activation='tanh', batch_size='auto', solver='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\"hidden_layer_sizes\": [(sp_randint.rvs(500,600,1),)],\n",
    "              \"max_iter\": sp_randint(1, 200),\n",
    "              \"alpha\": [1e-3, 1e-5],\n",
    "              \"verbose\": sp_randint(20, 25),\n",
    "              \"random_state\": sp_randint(50, 70),\n",
    "              \"tol\": [1e-16, 1e-20]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 5\n",
    "random_search = RandomizedSearchCV(mlp_clf, param_distributions=param_dist,\n",
    "                                       n_iter=n_iter_search, cv=5, iid=False)\n",
    "random_search.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search.best_score_)\n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.19988014\n",
      "Iteration 2, loss = 1.07117986\n",
      "Iteration 3, loss = 1.05633714\n",
      "Iteration 4, loss = 1.04670469\n",
      "Iteration 5, loss = 1.04050338\n",
      "Iteration 6, loss = 1.04083620\n",
      "Iteration 7, loss = 1.02398924\n",
      "Iteration 8, loss = 1.00986585\n",
      "Iteration 9, loss = 1.01047215\n",
      "Iteration 10, loss = 0.99102795\n",
      "Iteration 11, loss = 0.98675271\n",
      "Iteration 12, loss = 0.97218421\n",
      "Iteration 13, loss = 0.96354806\n",
      "Iteration 14, loss = 0.95775868\n",
      "Iteration 15, loss = 0.95606784\n",
      "Iteration 16, loss = 0.94189115\n",
      "Iteration 17, loss = 0.93014436\n",
      "Iteration 18, loss = 0.92452047\n",
      "Iteration 19, loss = 0.91154621\n",
      "Iteration 20, loss = 0.91387474\n",
      "Iteration 21, loss = 0.91132024\n",
      "Iteration 22, loss = 0.91213263\n",
      "Iteration 23, loss = 0.88993892\n",
      "Iteration 24, loss = 0.87682722\n",
      "Iteration 25, loss = 0.90030387\n",
      "Iteration 26, loss = 0.86795416\n",
      "Iteration 27, loss = 0.86257380\n",
      "Iteration 28, loss = 0.86956788\n",
      "Iteration 29, loss = 0.85629329\n",
      "Iteration 30, loss = 0.84132864\n",
      "Iteration 31, loss = 0.83621558\n",
      "Iteration 32, loss = 0.85082494\n",
      "Iteration 33, loss = 0.83187085\n",
      "Iteration 34, loss = 0.82278885\n",
      "Iteration 35, loss = 0.82475711\n",
      "Iteration 36, loss = 0.82596851\n",
      "Iteration 37, loss = 0.83186968\n",
      "Iteration 38, loss = 0.82138802\n",
      "Iteration 39, loss = 0.81701839\n",
      "Iteration 40, loss = 0.84961029\n",
      "Iteration 41, loss = 0.83808522\n",
      "Iteration 42, loss = 0.80314079\n",
      "Iteration 43, loss = 0.83266826\n",
      "Iteration 44, loss = 0.81468642\n",
      "Iteration 45, loss = 0.80724259\n",
      "Iteration 46, loss = 0.81057976\n",
      "Iteration 47, loss = 0.81430901\n",
      "Iteration 48, loss = 0.80101865\n",
      "Iteration 49, loss = 0.79902550\n",
      "Iteration 50, loss = 0.81324712\n",
      "Iteration 51, loss = 0.81784371\n",
      "Iteration 52, loss = 0.79850283\n",
      "Iteration 53, loss = 0.79239387\n",
      "Iteration 54, loss = 0.79085606\n",
      "Iteration 55, loss = 0.78962653\n",
      "Iteration 56, loss = 0.79577675\n",
      "Iteration 57, loss = 0.80476173\n",
      "Iteration 58, loss = 0.79290339\n",
      "Iteration 59, loss = 0.79675808\n",
      "Iteration 60, loss = 0.78072094\n",
      "Iteration 61, loss = 0.77410212\n",
      "Iteration 62, loss = 0.76954721\n",
      "Iteration 63, loss = 0.78684342\n",
      "Iteration 64, loss = 0.79429181\n",
      "Iteration 65, loss = 0.79531588\n",
      "Iteration 66, loss = 0.78224215\n",
      "Iteration 67, loss = 0.76946459\n",
      "Iteration 68, loss = 0.77795237\n",
      "Iteration 69, loss = 0.80096567\n",
      "Iteration 70, loss = 0.79951379\n",
      "Iteration 71, loss = 0.78364494\n",
      "Iteration 72, loss = 0.78724063\n",
      "Iteration 73, loss = 0.78595905\n",
      "Iteration 74, loss = 0.77020200\n",
      "Iteration 75, loss = 0.80835106\n",
      "Iteration 76, loss = 0.78393675\n",
      "Iteration 77, loss = 0.78428781\n",
      "Iteration 78, loss = 0.79475176\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "0.655792276964048\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(572,), learning_rate='constant',\n",
    "              learning_rate_init=0.001, max_iter=143, momentum=0.9,\n",
    "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "              random_state=60, shuffle=True, solver='adam', tol=1e-20,\n",
    "              validation_fraction=0.1, verbose=23, warm_start=False)\n",
    "mlp_clf.fit(x_train,y_train)\n",
    "y_pred = mlp_clf.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy scores\n",
    "<br> Spain: 0.6592729513247073\n",
    "<br> England:  0.6062846580406654\n",
    "<br> Germany:  0.6502057613168725\n",
    "<br> Italy:  0.655792276964048\n",
    "<br> France:  0.6425233644859814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "football = football.drop(columns = ['hTR'], axis = 1, errors='ignore')\n",
    "x,y = football.loc[:,football.columns != 'fTR'], football.loc[:,'fTR']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.18643290\n",
      "Iteration 2, loss = 1.07060253\n",
      "Iteration 3, loss = 1.06454977\n",
      "Iteration 4, loss = 1.06147431\n",
      "Iteration 5, loss = 1.05086898\n",
      "Iteration 6, loss = 1.04178756\n",
      "Iteration 7, loss = 1.03641537\n",
      "Iteration 8, loss = 1.04007046\n",
      "Iteration 9, loss = 1.01370463\n",
      "Iteration 10, loss = 0.99494163\n",
      "Iteration 11, loss = 0.98227816\n",
      "Iteration 12, loss = 0.96893706\n",
      "Iteration 13, loss = 0.96787918\n",
      "Iteration 14, loss = 0.96100331\n",
      "Iteration 15, loss = 0.94667363\n",
      "Iteration 16, loss = 0.94120600\n",
      "Iteration 17, loss = 0.94009725\n",
      "Iteration 18, loss = 0.95258414\n",
      "Iteration 19, loss = 0.95920229\n",
      "Iteration 20, loss = 0.94267077\n",
      "Iteration 21, loss = 0.91519868\n",
      "Iteration 22, loss = 0.93071892\n",
      "Iteration 23, loss = 0.92852334\n",
      "Iteration 24, loss = 0.91498455\n",
      "Iteration 25, loss = 0.91778234\n",
      "Iteration 26, loss = 0.90724708\n",
      "Iteration 27, loss = 0.91252750\n",
      "Iteration 28, loss = 0.90929159\n",
      "Iteration 29, loss = 0.90501780\n",
      "Iteration 30, loss = 0.89579263\n",
      "Iteration 31, loss = 0.90217780\n",
      "Iteration 32, loss = 0.89789425\n",
      "Iteration 33, loss = 0.89526188\n",
      "Iteration 34, loss = 0.89364892\n",
      "Iteration 35, loss = 0.88419605\n",
      "Iteration 36, loss = 0.88111335\n",
      "Iteration 37, loss = 0.88122663\n",
      "Iteration 38, loss = 0.87031456\n",
      "Iteration 39, loss = 0.90069870\n",
      "Iteration 40, loss = 0.89409547\n",
      "Iteration 41, loss = 0.87865599\n",
      "Iteration 42, loss = 0.87417976\n",
      "Iteration 43, loss = 0.86797886\n",
      "Iteration 44, loss = 0.86496175\n",
      "Iteration 45, loss = 0.86790241\n",
      "Iteration 46, loss = 0.87606863\n",
      "Iteration 47, loss = 0.86685197\n",
      "Iteration 48, loss = 0.86276957\n",
      "Iteration 49, loss = 0.85515186\n",
      "Iteration 50, loss = 0.86368155\n",
      "Iteration 51, loss = 0.86855004\n",
      "Iteration 52, loss = 0.85027633\n",
      "Iteration 53, loss = 0.86134569\n",
      "Iteration 54, loss = 0.85154400\n",
      "Iteration 55, loss = 0.85351033\n",
      "Iteration 56, loss = 0.86577238\n",
      "Iteration 57, loss = 0.85990250\n",
      "Iteration 58, loss = 0.85594783\n",
      "Iteration 59, loss = 0.86922939\n",
      "Iteration 60, loss = 0.87820107\n",
      "Iteration 61, loss = 0.87559777\n",
      "Iteration 62, loss = 0.86364443\n",
      "Iteration 63, loss = 0.85665456\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "0.5572569906790945\n"
     ]
    }
   ],
   "source": [
    "mlp_clf.fit(x_train,y_train)\n",
    "y_pred = mlp_clf.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy scores\n",
    "<br> Spain: 0.609981515711645\n",
    "<br> England:  0.5847196549599507\n",
    "<br> Germany:  0.5530864197530864\n",
    "<br> Italy:  0.5572569906790945\n",
    "<br> France:  0.5661993769470405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "football = football.drop(columns = ['HST', 'AST', 'HS', 'AS', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR'], axis = 1, errors='ignore')\n",
    "x,y = football.loc[:,football.columns != 'fTR'], football.loc[:,'fTR']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.08005416\n",
      "Iteration 2, loss = 1.06474227\n",
      "Iteration 3, loss = 1.04439378\n",
      "Iteration 4, loss = 1.03474344\n",
      "Iteration 5, loss = 1.02702872\n",
      "Iteration 6, loss = 1.02107388\n",
      "Iteration 7, loss = 1.01116052\n",
      "Iteration 8, loss = 1.00973479\n",
      "Iteration 9, loss = 0.99241756\n",
      "Iteration 10, loss = 1.00812999\n",
      "Iteration 11, loss = 0.98477077\n",
      "Iteration 12, loss = 0.97939952\n",
      "Iteration 13, loss = 0.98621084\n",
      "Iteration 14, loss = 0.98971848\n",
      "Iteration 15, loss = 0.98729713\n",
      "Iteration 16, loss = 0.98517658\n",
      "Iteration 17, loss = 0.98484316\n",
      "Iteration 18, loss = 0.99070764\n",
      "Iteration 19, loss = 0.99344397\n",
      "Iteration 20, loss = 0.99030985\n",
      "Iteration 21, loss = 0.99281670\n",
      "Iteration 22, loss = 1.01672294\n",
      "Iteration 23, loss = 0.99943795\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "0.5255699322242761\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(activation='tanh', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(75, 264), learning_rate='constant',\n",
    "              learning_rate_init=0.001, max_iter=164, momentum=0.9,\n",
    "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "              random_state=51, shuffle=True, solver='adam', tol=1e-21,\n",
    "              validation_fraction=0.1, verbose=22, warm_start=False)\n",
    "\n",
    "mlp_clf.fit(x_train,y_train)\n",
    "y_pred = mlp_clf.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy scores\n",
    "<br> Spain: 0.5255699322242761\n",
    "<br> England:  0.5200246457178065\n",
    "<br> Germany:  0.4576131687242798\n",
    "<br> Italy:  0.5286284953395473\n",
    "<br> France:  0.42601246105919005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1127 23:19:18.872809 140635143837504 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1127 23:19:18.873512 140635143837504 deprecation.py:323] From <ipython-input-12-8aeb73b4bf86>:3: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "W1127 23:19:18.874481 140635143837504 deprecation.py:323] From <ipython-input-12-8aeb73b4bf86>:5: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "W1127 23:19:18.875277 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "W1127 23:19:18.876111 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:96: extract_dask_data (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "W1127 23:19:18.876949 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "W1127 23:19:18.881047 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "W1127 23:19:18.883419 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please convert numpy dtypes explicitly.\n",
      "W1127 23:19:18.884287 140635143837504 data_feeder.py:283] float64 is not supported by many models, consider casting to float32.\n",
      "W1127 23:19:18.886868 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "W1127 23:19:18.891276 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "W1127 23:19:18.892588 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "W1127 23:19:18.897638 140635143837504 estimator.py:453] Using temporary folder as model directory: /tmp/tmppe71pnrv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 23:19:18.900870 140635143837504 deprecation.py:323] From <ipython-input-12-8aeb73b4bf86>:8: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to the Estimator interface.\n",
      "W1127 23:19:18.903003 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "W1127 23:19:18.908607 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "W1127 23:19:18.911802 140635143837504 data_feeder.py:283] float64 is not supported by many models, consider casting to float32.\n",
      "W1127 23:19:18.923585 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1127 23:19:19.614188 140635143837504 deprecation.py:506] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1127 23:19:19.818767 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "W1127 23:19:19.959151 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # nieukazane w konfiguracji\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[500,150,60], n_classes=3,\n",
    "                                         feature_columns=feature_cols)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # jeśli wersja modułu TensorFlow >= 1.1\n",
    "dnn_clf.fit(x_train, y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 23:21:53.701781 140635143837504 data_feeder.py:283] float64 is not supported by many models, consider casting to float32.\n",
      "W1127 23:21:53.946984 140635143837504 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6189300411522634"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Spain: 0.6518\n",
    "<br> England: 0.6457\n",
    "<br> Italy: 0.6657\n",
    "<br> France: 0.6370\n",
    "<br> Germany: 0.6189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "football = football.drop(columns = ['hTR'], axis = 1, errors='ignore')\n",
    "x,y = football.loc[:,football.columns != 'fTR'], football.loc[:,'fTR']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 23:23:40.596573 140635143837504 data_feeder.py:283] float64 is not supported by many models, consider casting to float32.\n",
      "W1127 23:23:40.600509 140635143837504 estimator.py:453] Using temporary folder as model directory: /tmp/tmpnnzw5apq\n",
      "W1127 23:23:40.602615 140635143837504 data_feeder.py:283] float64 is not supported by many models, consider casting to float32.\n",
      "W1127 23:27:09.813768 140635143837504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 36622 vs previous value: 36622. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # nieukazane w konfiguracji\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
    "\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[500,150,60], n_classes=3,\n",
    "                                         feature_columns=feature_cols)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # jeśli wersja modułu TensorFlow >= 1.1\n",
    "\n",
    "dnn_clf.fit(x_train, y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 23:27:29.107645 140635143837504 data_feeder.py:283] float64 is not supported by many models, consider casting to float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5489711934156378"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Spain: 0.5927\n",
    "<br> England: 0.5582\n",
    "<br> Italy: 0.5985\n",
    "<br> France: 0.5919\n",
    "<br> Germany: 0.5489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "football = football.drop(columns = ['HST', 'AST', 'HS', 'AS', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR'], axis = 1, errors='ignore')\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kub/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1128 16:56:28.975899 140479335855936 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1128 16:56:28.976907 140479335855936 deprecation.py:323] From <ipython-input-17-9095dc6402cd>:4: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "W1128 16:56:28.977896 140479335855936 deprecation.py:323] From <ipython-input-17-9095dc6402cd>:5: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "W1128 16:56:28.978846 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "W1128 16:56:28.979656 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:96: extract_dask_data (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "W1128 16:56:28.980327 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "W1128 16:56:28.983868 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "W1128 16:56:28.985027 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please convert numpy dtypes explicitly.\n",
      "W1128 16:56:28.985638 140479335855936 data_feeder.py:283] float64 is not supported by many models, consider casting to float32.\n",
      "W1128 16:56:28.988284 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "W1128 16:56:28.997483 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "W1128 16:56:28.998640 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "W1128 16:56:29.000055 140479335855936 estimator.py:453] Using temporary folder as model directory: /tmp/tmpeghky131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1128 16:56:29.003450 140479335855936 deprecation.py:323] From <ipython-input-17-9095dc6402cd>:8: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to the Estimator interface.\n",
      "W1128 16:56:29.005709 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "W1128 16:56:29.008854 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "W1128 16:56:29.010015 140479335855936 data_feeder.py:283] float64 is not supported by many models, consider casting to float32.\n",
      "W1128 16:56:29.031114 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1128 16:56:29.711710 140479335855936 deprecation.py:506] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1128 16:56:29.934977 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "W1128 16:56:30.039533 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1128 16:56:40.966968 140479335855936 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3495 vs previous value: 3495. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W1128 16:58:31.844350 140479335855936 data_feeder.py:283] float64 is not supported by many models, consider casting to float32.\n",
      "W1128 16:58:32.194848 140479335855936 deprecation.py:323] From /home/kub/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5778816199376947"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # nieukazane w konfiguracji\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,120,30], n_classes=3, \n",
    "                                         activation_fn=tf.nn.elu, feature_columns=feature_cols)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # jeśli wersja modułu TensorFlow >= 1.1\n",
    "\n",
    "\n",
    "dnn_clf.fit(x_train, y_train, batch_size=50, steps=40000)\n",
    "y_pred = dnn_clf.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Spain: 0.4664\n",
    "<br> England: 0.5520\n",
    "<br> Italy: 0.4480\n",
    "<br> France: 0.5778\n",
    "<br> Germany: 0.5390"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
